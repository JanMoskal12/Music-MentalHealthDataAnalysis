---
title: "Modeling"
author: "Szymon Makulec"
date: "2025-05-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE, message=FALSE, warning=FALSE}
library(tidymodels)
library(doParallel)
```

```{r}
df <- readRDS("data_no_missing_values.rds")
```


```{r}
set.seed(123)
df_split <- initial_split(df, prop = 0.7, strata = "Depression")
df_train <- training(df_split)
df_test <- testing(df_split)

models <- list(
  rf = rand_forest(
    trees = tune(),
    min_n = tune(),
    mtry = tune(),
    mode = "classification") %>%
    set_engine("ranger"),
  
  xgb = boost_tree(
    trees = tune(),
    min_n = tune(),
    mtry = tune(),
    learn_rate = tune(),
    mode = "classification") %>%
    set_engine("xgboost"),
  
  svm = svm_rbf(
    cost = tune(),
    rbf_sigma = tune(),
    mode = "classification") %>%
    set_engine("kernlab")
  
)

recipes <- list(
  rec_norm = recipe(Depression ~ ., data = df_train) %>%
    step_normalize(all_numeric_predictors() )  %>%
    step_dummy(all_nominal_predictors()),

  rec_pca = recipe(Depression ~ ., data = df_train) %>%
    step_normalize(all_numeric_predictors()) %>%
    step_dummy(all_nominal_predictors()) %>%
    step_pca(all_predictors(), threshold = 0.95)
)

cv_folds <- vfold_cv(df_train, v = 5, strata = "Depression")

class_models <- workflow_set(
  preproc = recipes,
  models = models,
  cross = TRUE
)

```

```{r}
registerDoParallel(cores = parallel::detectCores() - 1)


class_models <- workflow_map(
  class_models,
  "tune_grid", 
  resamples = cv_folds,
  grid = 20,
  control = control_grid(save_pred = TRUE, save_workflow = TRUE)
)


saveRDS(class_models, "mxmh_model.rds")
```

### Ocena modeli

```{r}
class_models <- readRDS("mxmh_model.rds")
metryki <- collect_metrics(class_models)

metryki
```


### Najlepsze modele dla wybranych metryk

```{r}
selected_metrics <- c("accuracy", "kap", "mn_log_loss", "brier_class")

top3_models_per_metric <- metryki %>%
  filter(.metric %in% selected_metrics) %>%
  group_by(.metric) %>%
  mutate(ranking = if_else(.metric %in% c("mn_log_loss", "brier_class"),
                           rank(mean, ties.method = "first"),  # im mniejsze, tym lepsze
                           rank(-mean, ties.method = "first"))) %>%  # im większe, tym lepsze
  filter(ranking <= 3) %>%
  arrange(.metric, ranking) %>%
  select(.metric, model, mean, ranking)

print(top3_models_per_metric)
```

```{r}
available_metrics <- unique(metryki$.metric)

# Posortowanie i wybranie najlepszych modeli dla każdej metryki
top_models <- metryki %>%
  group_by(.metric) %>%
  mutate(ranking = if_else(
    .metric %in% c("brier_class", "mn_log_loss"),
    rank(mean, ties.method = "first"),     # niższa wartość = lepsza
    rank(-mean, ties.method = "first")     # wyższa wartość = lepsza
  )) %>%
  filter(ranking <= 3) %>%
  arrange(.metric, ranking) %>%
  ungroup()

print(top_models)
```



