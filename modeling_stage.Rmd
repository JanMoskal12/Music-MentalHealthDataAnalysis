---
title: "Music & Mental Health - Modeling Stage"
author: "Jan Moskal i Szymon Makulec"
date: "2025-05-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE, message=FALSE, warning=FALSE}
library(tidymodels)
library(doParallel)
library(discrim)
library(mda)
```


### Wczytanie danych
```{r}
df <- readRDS("data_no_missing_values.rds")
```

### Podział danych na zbiór treningowy i testowy
```{r}
set.seed(123)

df_split <- initial_split(df, prop = 0.7, strata = "Depression")
df_train <- training(df_split)
df_test <- testing(df_split)
```

### Inicjalizacja modeli do uczenia
```{r}
models <- list(
            lda = discrim_linear(
              regularization_method = "diagonal",
              penalty = tune(),
              mode = "classification") %>% 
              set_engine("mda"),
              
            rf = rand_forest(
              trees = tune(),
              min_n = tune(),
              mtry = tune(),
              mode = "classification") %>%
              set_engine("ranger"),
  
            xgb = boost_tree(
              trees = tune(),
              min_n = tune(),
              mtry = tune(),
              learn_rate = tune(),
              mode = "classification") %>%
              set_engine("xgboost"),
  
            svm = svm_rbf(
              cost = tune(),
              rbf_sigma = tune(),
              mode = "classification") %>%
              set_engine("kernlab")
)
```

### Utworzenie przepisów przetwarzania danych
```{r}
recipes <- list(
            rec_lda = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(all_predictors(), threshold = 0.8),
            
            rec_rf = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors())  %>%
                        step_dummy(all_nominal_predictors()) %>% 
                        step_pca(all_predictors(), threshold = 0.8),

            rec_xgb = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(all_predictors(), threshold = 0.6),
            
            rec_svm = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(all_predictors(), threshold = 0.6)
)
```

### Utworzenie przepływów modelowania
```{r}
class_models <- workflow_set(
                  preproc = recipes,
                  models = models,
                  cross = FALSE
)
```

### Generowanie foldów walidacyjnych
```{r}
cv_folds <- vfold_cv(df_train, v = 5, strata = "Depression")
```

### Trenowanie modeli z walidacją krzyżową i tuningiem siatki hiperparametrów
```{r}
registerDoParallel(cores = parallel::detectCores() - 1)
controlGrid <- control_grid(save_pred = TRUE, save_workflow = TRUE)

class_models <- workflow_map(
                  class_models,
                  "tune_grid", 
                  resamples = cv_folds,
                  grid = 20,
                  control = controlGrid
)
```

### Zapisywanie wyników 
```{r}
#saveRDS(class_models, "mxmh_models.rds")
```

### Ocena modeli
```{r}
class_models <- readRDS("mxmh_models.rds")
metrics <- collect_metrics(class_models)

metrics %>% 
  arrange(.metric, desc(mean))
```

### Najlepsze modele dla wybranych metryk
```{r}
selected_metrics <- c("accuracy", "kap", "mn_log_loss", "brier_class")

top3_models_per_metric <- metrics %>%
                            filter(.metric %in% selected_metrics) %>%
                            group_by(.metric) %>%
                            mutate(ranking = if_else(.metric %in% c("mn_log_loss", "brier_class"),
                                                     rank(mean, ties.method = "first"),  # im mniejsze, tym lepsze
                                                     rank(-mean, ties.method = "first"))) %>%  # im większe, tym lepsze
                            filter(ranking <= 3) %>%
                            arrange(.metric, ranking) %>%
                            select(.metric, model, mean, ranking)

print(top3_models_per_metric)
```

```{r}
available_metrics <- unique(metrics$.metric)

# Posortowanie i wybranie najlepszych modeli dla każdej metryki
top_models <- metrics %>%
                group_by(.metric) %>%
                mutate(ranking = if_else(
                                  .metric %in% c("brier_class", "mn_log_loss"),
                                  rank(mean, ties.method = "first"),     # niższa wartość = lepsza
                                  rank(-mean, ties.method = "first")     # wyższa wartość = lepsza
                )) %>%
                filter(ranking <= 3) %>%
                arrange(.metric, ranking) %>%
                ungroup()

print(top_models)
```