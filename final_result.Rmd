---
title: "Music & Mental Health"
author: "Jan Moskal i Szymon Makulec"
date: "2025-05-31"
output: html_document
---

```{r setup, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include=FALSE, warning=FALSE, message=FALSE}
library(tidymodels)
library(tidyverse)
library(kableExtra)
library(ggcorrplot)
library(patchwork)
library(DescTools)
library(doParallel)
library(discrim)
library(baguette)
library(Metrics)
library(themis)
library(scales)
library(e1071)
library(mice)
library(VIM)
library(mda)
```

```{r, include=FALSE}
plot_distribution <- function(df, var, title, xlab, fill_colors = NULL){
  df %>%
    drop_na({{var}}) %>%
    mutate({{var}} := fct_infreq({{var}})) %>%
    ggplot(aes(x = {{var}}, fill = {{var}})) +
    geom_bar() +
    theme_minimal() +
    theme(legend.position = "none", axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(title = title, x = xlab, y = "Liczba osób")
}

plot_boxplot <- function(df, xvar, yvar, title, xlab, ylab){
  df %>%
    drop_na({{yvar}}) %>% 
    mutate({{xvar}} := factor({{xvar}}, levels = c("Low", "Medium", "High"))) %>%
    ggplot(aes(x = {{xvar}}, y = {{yvar}}, fill = {{xvar}})) +
    geom_boxplot() +
    theme_minimal() +
    theme(legend.position = "none") +
    labs(title = title, x = xlab, y = ylab)
}

plot_prop_bar <- function(df, fill_var, title, xlab, ylab, fill_lab){
  df %>%
    drop_na(Depression, {{fill_var}}) %>%
    mutate(Depression = factor(Depression, levels = c("Low", "Medium", "High"))) %>%
    group_by(Depression, {{fill_var}}) %>%
    summarise(count = n(), .groups = "drop") %>%
    group_by(Depression) %>%
    mutate(prop = count / sum(count)) %>%
    ggplot(aes(x = Depression, y = prop, fill = {{fill_var}})) +
    geom_bar(stat = "identity", position = "stack") +
    theme_minimal() +
    labs(title = title, x = xlab, y = ylab, fill = fill_lab)
}

plot_mean_barplot <- function(df, variable, title, y_lab){
  df %>%
    group_by(Frequency) %>%
    summarise(mean_val = mean(.data[[variable]], na.rm = TRUE), .groups = "drop") %>%
    ggplot(aes(x = Frequency, y = mean_val, fill = Frequency)) +
    geom_col(width = 0.6) +
    geom_text(aes(label = round(mean_val, 2)), vjust = -0.5, size = 4) +
    scale_fill_brewer(palette = "Blues") +
    theme_minimal() +
    theme(legend.position = "none") +
    labs(title = title, x = "Częstotliwość słuchania", y = y_lab)
}

plot_heatmap <- function(df, title, fill_label){
  df %>% 
    ggplot(aes(x = Genre, y = Frequency, fill = mean_val)) +
    geom_tile(color = "white") +
    geom_text(aes(label = round(mean_val, 2)), size = 3, color = "black") +
    scale_fill_gradient(low = "lightblue", high = "darkred") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1), panel.grid = element_blank()) +
    labs(title = title, x = "Gatunek", y = "Częstotliwość słuchania", fill = fill_label)
}

plot_mean_heatmap <- function(df, variable, title, fill){
  df %>% 
    pivot_longer(cols = all_of(freq_cols), names_to = "Genre", values_to = "Frequency") %>% 
    mutate(Genre = str_remove_all(Genre, "Frequency \\[|\\]")) %>% 
    group_by(Genre, Frequency) %>% 
    summarise(mean_val = mean(.data[[variable]], na.rm = TRUE), .groups = "drop") %>% 
    plot_heatmap(title = title, fill_label = fill)
}

plot_binary_heatmap <- function(df, variable) {
  df %>%
    group_by(Genre, Frequency) %>%
    summarise(Count = sum(.data[[variable]] == "Yes", na.rm = TRUE), Total = n(), Prop = Count / Total, .groups = "drop") %>%
    ggplot(aes(x = Genre, y = Frequency, fill = Prop)) +
    geom_tile(color = "white") +
    geom_text(aes(label = round(Prop, 2)), color = "black", size = 3) +
    scale_fill_gradient(low = "lightblue", high = "darkred") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    labs(x = "Gatunek", y = "Częstotliwość słuchania", fill = "Proporcja")
}

adjust_levels <- function(pred_df) {
  pred_df$.pred_class <- factor(pred_df$.pred_class, levels = levels_order, ordered = TRUE)
  pred_df$Depression <- factor(pred_df$Depression, levels = levels_order, ordered = TRUE)
  pred_df
}

get_metrics <- function(pred_df) {
  metric_set(mn_log_loss, kap)(
    pred_df,
    truth = Depression,
    estimate = .pred_class,
    .pred_Low, .pred_Medium, .pred_High
  )
}
```

## Wstęp

#### Cel projektu

Głównym celem analizy jest opracowanie modelu klasyfikacyjnego, który umożliwi przewidywanie poziomu nasilenia zmiennej `Depression` (niskie, średnie, wysokie). Chcemy sprawdzić, czy dane dotyczące sposobu słuchania muzyki, codziennych nawyków oraz częstotliwości słuchania konkretnych gatunków muzycznych itd. mogą być pomocne w przewidywaniu poziomu samopoczucia psychicznego, a konkretnie nasilenia objawów depresyjnych.

#### Opis danych

Dane pochodzą ze zbioru dostępnego na stronie [Kaggle](https://www.kaggle.com/datasets/catherinerasgaitis/mxmh-survey-results/data), który zawiera odpowiedzi respondentów na temat ich zwyczajów związanych ze słuchaniem muzyki oraz samooceny zdrowia psychicznego. Dane te mogą być pomocne w identyfikacji potencjalnych zależności między stylem życia muzycznego a samopoczuciem psychicznym.

#### Opis zmiennych

| Zmienna | Opis | Typ |
|----------------|-----------------------------------------|----------------|
| Timestamp | Data i czas przesłania formularza | datetime |
| Age | Wiek respondenta | numeric |
| Primarystreamingservice | Główna platforma streamingowa używana przez respondenta | factor |
| Hoursperday | Liczba godzin dziennie, przez które respondent słucha muzyki | numeric |
| Whileworking | Czy respondent słucha muzyki podczas nauki/pracy? | factor |
| Instrumentalist | Czy respondent regularnie gra na instrumencie? | factor |
| Composer | Czy respondent komponuje muzykę? | factor |
| Favgenre | Ulubiony gatunek muzyczny respondenta | factor |
| Exploratory | Czy respondent aktywnie odkrywa nowych artystów/gatunki? | factor |
| Foreignlanguages | Czy respondent regularnie słucha muzyki z tekstami w języku, którego nie zna biegle? | factor |
| BPM | Liczba uderzeń na minutę w ulubionym gatunku muzycznym | numeric |
| Frequency[Classical] | Jak często respondent słucha muzyki klasycznej? | factor |
| Frequency[Country] | Jak często respondent słucha muzyki country? | factor |
| Frequency[EDM] | Jak często respondent słucha muzyki EDM? | factor |
| Frequency[Folk] | Jak często respondent słucha muzyki folkowej? | factor |
| Frequency[Gospel] | Jak często respondent słucha muzyki gospel? | factor |
| Frequency[Hiphop] | Jak często respondent słucha muzyki hip-hop? | factor |
| Frequency[Jazz] | Jak często respondent słucha muzyki jazzowej? | factor |
| Frequency[Kpop] | Jak często respondent słucha muzyki K-pop? | factor |
| Frequency[Latin] | Jak często respondent słucha muzyki latynoskiej? | factor |
| Frequency[Lofi] | Jak często respondent słucha muzyki lo-fi? | factor |
| Frequency[Metal] | Jak często respondent słucha muzyki metalowej? | factor |
| Frequency[Pop] | Jak często respondent słucha muzyki pop? | factor |
| Frequency[R&B] | Jak często respondent słucha muzyki R&B? | factor |
| Frequency[Rap] | Jak często respondent słucha muzyki rap? | factor |
| Frequency[Rock] | Jak często respondent słucha muzyki rockowej? | factor |
| Frequency[Videogame music] | Jak często respondent słucha muzyki z gier wideo? | factor |
| Anxiety | Nasilenie stanów lękowych w skali 0–10 | ordered factor |
| Depression | Nasilenie depresji w skali 0–10 | factor |
| Insomnia | Nasilenie problemów ze snem w skali 0–10 | ordered factor |
| OCD | Nasilenie zaburzeń obsesyjno-kompulsyjnych w skali 0–10 | ordered factor |
| Music effects | Subiektywny wpływ muzyki na zdrowie psychiczne | factor |
| Permissions | Zgoda na wykorzystanie danych | factor |

## Wstępne przygotowanie danych

### Wczytanie i obróbka danych

```{r, message=FALSE}
df <- read_csv("mxmh_survey_results.csv", col_names = TRUE)
```

#### Usuwanie zbędnych zmiennych

```{r}
df <- df %>% 
        select(-c(Timestamp, Anxiety, Insomnia, OCD, `Music effects`, Permissions))
```

Usuwamy zmienne niezwiązane bezpośrednio z analizowaną problematyką (Timestamp, Permissions). Pozostałe zmienne są poza zakresem analizy lub same mogą być przewidywane, więc nie powinny być predyktorami.

```{r}
glimpse(df)
```

Po usunięciu niepotrzebnych zmiennych w zbiorze zostało 27 kolumn, z czego większość to narazie zmienne tekstowe, jednak po zmianach będą to zmienne czynnikowe (często uporządkowane). Mamy też kilka zmiennych numerycznych. Mamy 736 obserwacje, gdzie każda oznacza wypełnienie ankiety przez jedną osobę.

#### Ustawianie odpowiedniej kolejności poziomów w zmiennych dotyczących częstotliwości słuchania konkretnych gatunków

```{r}
custom_levels <- c("Never", "Rarely", "Sometimes", "Very frequently")

df <- df %>% 
        mutate(across(`Frequency [Classical]`:`Frequency [Video game music]`, function(x) factor(x, levels = custom_levels, ordered = TRUE)))
```

Wszystkie kolumny dotyczące częstotliwości słuchania danych zamieniamy na uporządkowane kategoryczne, ponieważ widać w ich przypadku naturalny porządek kategorii.

#### Ustawienie pozostałych zmiennych typu tekstowego na zmienne kategoryczne

```{r}
df <- df %>% 
        mutate(across(`While working`:`Foreign languages`, as.factor),
               `Primary streaming service` = as.factor(`Primary streaming service`))
```

Pozostałe zmienne tekstowe zamieniamy na zmienne kategoryczne. Są tutaj zmienne, które przyjmują wiele wartości tzn. `Primary streaming service`, `Fav genre` oraz zmienne binarne (pozostałe).

#### Zapisanie ramki danych po przekształceniach

```{r}
#saveRDS(df, "df.rds")
```

```{r, include=FALSE}
df <- df %>% 
  mutate(Age = cut(Age, breaks = c(0, 22, 40, Inf), labels = c("Youth", "Adult", "Senior"), right = TRUE))
```

#### Zamiana zmiennej objaśnianej z typu numerycznego na typ kategoryczny z trzema kategoriami

```{r}
quantiles <- quantile(df$Depression, probs = c(0.33, 0.66), na.rm = TRUE)
```

```{r, echo=FALSE, warning=FALSE}
df %>%
  ggplot(aes(x = Depression)) +
  geom_histogram(binwidth = 1, fill = "lightblue", color = "black") +
  geom_vline(xintercept = quantiles, color = "red", linetype = "dashed", size = 1) +
  labs(title = "Histogram poziomu depresji",
       x = "Poziom depresji", y = "Liczba wystąpień")
```

```{r}
df <- df %>%
  mutate(Depression = case_when(
    Depression <= quantiles[1] ~ "Low", # 0-3
    Depression > quantiles[1] & Depression < quantiles[2] ~ "Medium", # 4-6
    Depression >= quantiles[2] ~ "High" # 7-10
  ))
```

Rozpatrywanie zmiennej poziomu depresji w skali 0–10 byłoby problematyczne ze względu na dużą liczbę klas oraz wątpliwą interpretowalność drobnych różnic. Różnice między niskimi wartościami (np. 0, 1, 2) mogą być nieistotne, ponieważ osoby zaznaczające te poziomy zazwyczaj chcą jedynie zaznaczyć brak objawów depresyjnych. Podobnie wartości wysokie mogą być traktowane ogólnie jako wskazanie poważniejszych problemów, niezależnie od dokładnej liczby. Choć skrajne wartości mogą świadczyć o większej pewności odpowiedzi, zdecydowaliśmy się na przekształcenie tej zmiennej w trzy kategorie: Low, Medium i High. Podziału dokonano na podstawie kwantyli.

```{r, echo=FALSE}
df %>% 
  mutate(Depression = factor(Depression, levels = c("Low", "Medium", "High"))) %>% 
  ggplot(aes(x = Depression, fill = Depression)) + 
  geom_bar() +
  theme_minimal() +
  theme(legend.position = "none") +
  labs(title = "Rozkład poziomu depresji", x = "Poziom depresji", y = "Lcizba osób")
```

Jak widać, dane są dość zbalansowane – liczba obserwacji dla skrajnych poziomów (niskiego i wysokiego) jest nieco większa. Pozostawiamy ten podział bez zmian, ponieważ mniejsza liczba obserwacji w kategorii średniej nie jest problemem – to właśnie w tej grupie trudniej jednoznacznie określić stan respondenta. W przypadku poziomów niskiego i wysokiego można z większym prawdopodobieństwem założyć, że dana osoba odpowiednio nie doświadcza lub wyraźnie doświadcza objawów.

#### Zapisanie ramki danych po czyszczeniu i transformacji danych do EDA

```{r}
#saveRDS(df, "df_EDA.rds")
```

Na koniec zapisujemy zbiór, który posłuży nam do eksploracyjnej analizy danych.

## Eksploracyjna analiza danych

### Statystyki opisowe

#### Wczytywanie danych

```{r}
data <- readRDS("df_EDA.rds")
df <- readRDS("df.rds")
```

#### Podstawowe statystyki opisowe dla zmiennych numerycznych

```{r, echo=FALSE}
df %>%
  select(where(is.numeric)) %>%
  summary()
```

Warto zwrócić uwagę, że w dwóch kolumnach numerycznych występują braki danych – w `Age` tylko jedna, natomiast w `BPM` aż 107 obserwacji. Dodatkowo, w zmiennej `BPM` pojawiaja się wartość (lub wartości) znacznie odbiegająca od typowego zakresu BPM, zapewne jest to błąd. Wszystkie te kwestie zostaną w dalszej części odpowiednio przetworzone i rozwiązane.

#### Wykres macierzy korelacji dla zmiennych numerycznych

```{r, echo=FALSE}
df %>%
  select(where(is.numeric)) %>%
  cor(use = "complete.obs") %>%
  round(2) %>% 
  ggcorrplot(lab = TRUE)
```

Z analizy macierzy korelacji wynika, że nie występują istotne korelacje ani między zmiennymi objaśniającymi, ani pomiędzy nimi a zmienną objaśnianą – żadna wartość nie przekracza 0.1. Może to świadczyć o braku liniowych zależności w danych, co potencjalnie utrudnia skuteczne modelowanie i prognozowanie zmiennej objaśnianej.

#### Zestawienie liczby braków danych

```{r,echo=FALSE}
df %>%
  summarise_all(~sum(is.na(.))) %>%
  pivot_longer(everything(), names_to = "Zmienna", values_to = "Liczba braków") %>%
  filter(`Liczba braków` > 0) %>% 
  arrange(desc(`Liczba braków`))
```

W zbiorze danych występują braki w siedmiu zmiennych. Najwięcej braków odnotowano w zmiennej `BPM` (107), co będzie wymagać specjalnego potraktowania, zapewne imputacji. Pozostałe zmienne zawierają pojedyncze braki: `Instrumentalist` i `Foreign languages` po 4, `While working` – 3, `Age`, `Primary streaming service` i `Composer` – po 1. W tych sytuacjach planujemy usunięcie odpowiednich wierszy lub zastąpienie braków ustalonymi wartościami.

### Wykresy dotyczące zmiennych opisujących respondentów i ich ogólne zwyczaje muzyczne

#### Rozkład wieku słuchacza

```{r, echo=FALSE, warning=FALSE}
df %>% 
  ggplot(aes(x = Age)) +
  geom_histogram(color = "blue", fill = "lightblue", bins = 40) + 
  labs(title = "Rozkład wieku słuchacza", x = "Wiek słuchacza", y = "Liczba osób")
```

Wiek słuchaczy jest prawostronnie asymetryczny, z większością osób w przedziale 18-30 lat. Widać również trochę osób w wieku 50+.

#### Związek między wiekiem słuchającego a poziomem depresji

```{r, echo=FALSE, warning=FALSE}
df %>% 
  mutate(Depression = factor(case_when(Depression <= 3 ~ "Low", Depression > 3 & Depression < 7 ~ "Medium", Depression >= 7 ~ "High"),
                             levels = c("Low", "Medium", "High"), ordered = TRUE)) %>% 
  ggplot(aes(x = Depression, y = Age, fill = Depression)) + 
  geom_boxplot() + 
  theme_minimal() + 
  theme(legend.position = "none") +
  labs(title = "Związek między wiekiem słuchającego a poziomem depresji", x = "Poziom depresji", y = "Wiek słuchacza")
```

Dla niskiego poziomu depresji mamy największą różnorodność wieku słuchaczy co można zobaczyć po odległości między kwartylami. Dla średniego i wysokiego poziomu depresji mamy bardzo podobne rozkłady wieku. Im wyższy poziom depresji tym mediana wieku jest wyższa jednak nie jest ona dużo większa więc nie uznajemy tego za istotną różnicę.

#### Rozkład preferowanego serwisu streamingowego

```{r, echo=FALSE}
plot_distribution(data, `Primary streaming service`, "Rozkład preferowanego serwisu streamingowego", "Preferowany serwis streamingowy")
```

Większość słuchaczy korzysta z Spotify, a następnie z YouTube i Apple Music. Co ciekawe jest również trzecia co do wielkości grupa słuchaczy, która nie słucha muzyki w serwisach streamingowych.

#### Proporcje platform streamingowych wg poziomu depresji

```{r, echo=FALSE}
plot_prop_bar(data, `Primary streaming service`, "Proporcje platform streamingowych wg poziomu depresji", "Poziom depresji", "Udział", "Platforma streamingowa")
```

Dla kolejnych poziomów depresji zwiększa się ilość osób korzystających ze Spotify, a zmniejsza się ilość osób korzystających z YouTube Music oraz zmniejsza się liczba osób, które nie korzystają z serwisów streamingowych.

#### Rozkład dziennego czasu słuchania muzyki

```{r, echo=FALSE}
data %>% 
  ggplot(aes(x = `Hours per day`)) + 
  geom_histogram(color = "blue", fill = "lightblue", bins = 24) +
  theme_minimal() + 
  labs(title = "Rozkład dziennego czasu słuchania muzyki", x = "Liczba godzin", y = "Liczba osób")
```

Czas słuchania muzyki jest prawostronnie asymetryczny, z większością osób słuchających muzyki od 1 do 4 godzin dziennie. Widać również kilka osób słuchających muzyki przez ponad 10 godzin dziennie.

#### Związek między liczbą przesłuchanych godzin a poziomem depresji

```{r, echo=FALSE}
plot_boxplot(data, Depression, `Hours per day`, "Związek między liczbą przesłuchanych godzin a poziomem depresji", "Poziom depresji", "Liczba godzin")
```

Osoby z wyższym poziomem depresji mają tendencję do słuchania muzyki przez więcej godzin dziennie niż te z niższym poziomem depresji.

#### Rozkład ulubionego gatunku muzycznego

```{r, echo=FALSE}
plot_distribution(data, `Fav genre`, "Rozkład ulubionego gatunku muzycznego", "Ulubiony gatunek muzyczny", fill_colors = colors)
```

Ulubionymi gatunkami respondentów są głównie Rock, Pop oraz Metal.

#### Udział ulubionego gatunku wg poziomu depresji

```{r, echo=FALSE}
plot_prop_bar(data, `Fav genre`, "Udział ulubionego gatunku wg poziomu depresji", "Poziom depresji", "Udział", "Gatunek")
```

W grupie z wysoką depresją jest mniej osób słuchających metalu, muzyki z gier wideo, muzyki klasyczej, R&B. Rośnie za to liczba osób słuchających gatunków takich jak rock oraz hip hop.

#### Rozkład liczby uderzeń na minutę (BPM)

```{r, echo=FALSE}
data %>%
  drop_na(BPM) %>%
  filter(BPM < 500) %>%
  ggplot(aes(x = BPM)) + 
  geom_histogram(color = "blue", fill = "lightblue", bins = 22) +
  theme_minimal() + 
  labs(title = "Rozkład liczby uderzeń na minutę (BPM)", x = "Liczba uderzeń na minutę", y = "Liczba osób")
```

Liczba uderzeń na minutę jest w miarę symetryczna. Widoczne są obserwacje podejrzane jak BPM równe 0. Wartość BPM oscyluje wokół 120.

#### Związek między BPM ulubionego gatunku a poziomem depresji

```{r, echo=FALSE}
plot_boxplot(data %>% filter(BPM < 500), Depression, BPM, "Związek między BPM ulubionego gatunku a poziomem depresji", "Poziom depresji", "Uderzenia na minutę (BPM)")
```

Nie widać znaczącego wpływu BPM na poziom depresji. Istnieje jedynie podejrzenie, że osoby z niskim poziomem depresji słuchają muzyki o średnio niższym BPM.

#### Rozkład słuchania muzyki podczas pracy/nauki

```{r, echo=FALSE}
plot_distribution(data, `While working`, "Rozkład słuchania muzyki podczas pracy/nauki", "Słuchanie podczas pracy/nauki")
```

Znacząca większość osób słucha muzyki podczas pracy lub nauki.

#### Proporcje słuchania muzyki podczas pracy/nauki wg poziomu depresji

```{r, echo=FALSE}
plot_prop_bar(data, `While working`, "Proporcje słuchania muzyki podczas pracy/nauki wg poziomu depresji", "Poziom depresji", "Udział", "Słuchanie podczas pracy/nauki")
```

Osoby z wyższym poziomem depresji częściej słuchają muzyki podczas pracy lub nauki.

#### Rozkład gry na instrumencie

```{r, echo=FALSE}
plot_distribution(data, Instrumentalist, "Rozkład gry na instrumencie", "Regularne granie na instrumencie")
```

Jak można było się spodziewać znacząca większość osób nie gra na instrumencie. Jednakże ilość osób grających na instrumentach jest i tak dosyć duża.

#### Proporcje gry na instrumencie wg poziomu depresji

```{r, echo=FALSE}
plot_prop_bar(data, Instrumentalist, "Proporcje gry na instrumencie wg poziomu depresji", "Poziom depresji", "Udział", "Gra na instrumencie")
```

We wszystkich grupach ilość osób grających na instrumencie jest zbliżona.

#### Rozkład komponowania muzyki

```{r, echo=FALSE}
plot_distribution(data, Composer, "Rozkład komponowania muzyki", "Komponowanie muzyki")
```

Znacząca większość osób nie komponuje muzyki, osób komponujących jest około 110 co i tak jest wysokim wynikiem.

#### Proporcje komponowania muzyki wg poziomu depresji

```{r, echo=FALSE}
plot_prop_bar(data, Composer, "Proporcje komponowania muzyki wg poziomu depresji", "Poziom depresji", "Udział", "Komponowanie muzyki")
```

W grupie osób z wysoką depresją jest więcej osób komponujących muzykę. Może to jednak wynikać z faktu, że niewiele jest obserwacji w tej grupie.

#### Rozkład eksplorowania artystów/gatunków

```{r, echo=FALSE}
plot_distribution(data, Exploratory, "Rozkład eksplorowania artystów/gatunków", "Eksplorowanie artystów/gatunków")
```

Około 520 osób aktywnie eksploruje nowe gatunki oraz artystów. Około 210 osób tego nie czyni.

#### Proporcje eksplorowania artystów/gatunków wg poziomu depresji

```{r,echo=FALSE}
plot_prop_bar(data, Exploratory, "Proporcje eksplorowania artystów/gatunków wg depresji", "Poziom depresji", "Udział", "Eksplorowanie")
```

Osoby z wyższym poziomem depresji częściej eksplorują nowych artystów i gatunki muzyczne.

#### Rozkład słuchania w obcym języku

```{r, echo=FALSE}
plot_distribution(data, `Foreign languages`, "Rozkład słuchania w obcym języku", "Słuchanie w obcym języku")
```

Około 400 osób słucha muzyki w języku obcym zaś około 330 osób słucha muzyki jedynie w swoim ojczystym języku.

#### Proporcje słuchania w obcym języku wg depresji

```{r, echo=FALSE}
plot_prop_bar(data, `Foreign languages`, "Proporcje słuchania w obcym języku wg depresji", "Poziom depresji", "Udział", "Słuchanie w obcym języku")
```

Wraz ze wzrostem depresji rośnie liczba osób słuchających muzyki w obcym języku.

### Wykresy dotyczące zmiennych częstotliwości słuchania konkretnych gatunków

```{r, include=FALSE}
freq_cols <- grep("^Frequency \\[", names(data), value = TRUE)
freq_levels <- c("Never", "Rarely", "Sometimes", "Very frequently")

binary_vars <- c("Instrumentalist", "While working", "Composer", "Exploratory", "Foreign languages")

long_freq <- data %>%
              pivot_longer(cols = all_of(freq_cols), names_to = "Genre", values_to = "Frequency") %>%
              mutate(Genre = str_remove_all(Genre, "^Frequency \\[|\\]$"), Frequency = factor(Frequency, levels = freq_levels, ordered = TRUE))

df_depr <- data %>% 
            mutate(Depression = recode(Depression, "Low"= 0, "Medium" = 1, "High" = 2))

long_freq_count <- long_freq %>%
                    group_by(Genre, Frequency) %>%
                    summarise(count = n(), .groups = "drop")

long_freq_depr <- long_freq %>% 
                    mutate(Depression = recode(Depression,"Low"= 0, "Medium" = 1, "High" = 2),
                           Frequency_num = as.numeric(Frequency))

long_freq_age <- df %>% 
                  pivot_longer(cols = all_of(freq_cols), names_to = "Genre", values_to = "Frequency") %>%
                  mutate(Genre = str_remove_all(Genre, "^Frequency \\[|\\]$"), Frequency = factor(Frequency, levels = freq_levels, ordered = TRUE))

long_bin_all <- data %>%
                  select(all_of(freq_cols), all_of(binary_vars)) %>%
                  pivot_longer(cols = all_of(freq_cols), names_to = "Genre", values_to = "Frequency") %>%
                  mutate(Genre = str_remove_all(Genre, "Frequency \\[|\\]"))
```

#### Liczba osób słuchających danego gatunku z określoną częstotliwością słuchania

```{r, echo=FALSE}
long_freq %>% 
  count(Genre, Frequency) %>% 
  ggplot(aes(x = Genre, y = Frequency, fill = n)) +
  geom_tile(color = "white") +
  geom_text(aes(label = n), color = "black", size = 3) + 
  scale_fill_gradient(low = "lightyellow", high = "steelblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Liczba osób słuchających danego gatunku z określoną częstotliwością słuchania", x = "Gatunek", y = "Częstotliwość słuchania", fill = "Liczba osób")
```

Najwięcej osób bardzo często słucha muzyki pop i rock, co nie dziwi – są to jedne z najpopularniejszych gatunków muzycznych. Rzadko zdarza się natomiast, by respondenci w ogóle nie słuchali tych dwóch stylów. Z kolei niewielki odsetek badanych deklaruje częste słuchanie takich gatunków jak gospel, country, latin czy jazz. Może to wynikać z ich mniejszej popularności wśród młodszych odbiorców oraz postrzegania ich jako bardziej egzotycznych. Warto również zauważyć, że bardzo wiele osób nigdy nie słuchało muzyki gospel, k-popu, latin lub country, co może być związane z kulturowym lub religijnym kontekstem tych gatunków.Możliwy wpływ ma również dostępność tych gatunków w mediach i na platformach streamingowych, a także język utworów – gatunki nieanglojęzyczne mogą być mniej przystępne.

```{r, echo=FALSE}
plot_mean_barplot(long_freq_count, "count", "Średnia liczba osób słuchających według częstotliwości słuchania", "Średnia liczba osób") +
  ylim(0, 300)
```

Średnia liczba osób przypadająca na poszczególne poziomy częstotliwości słuchania maleje wraz ze wzrostem intensywności słuchania. Najwięcej osób średnio deklaruje, że nigdy nie słucha danego gatunku muzyki (268,69), a najmniej – że słucha go bardzo często (113,81). Może to sugerować, że większość gatunków muzycznych jest słuchana okazjonalnie lub wcale, a intensywne słuchanie ogranicza się do wybranych, popularnych stylów.

#### Średni poziom depresji w zależności od gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_mean_heatmap(df_depr, "Depression", "Średni poziom depresji w zależności od gatunku i częstotliwości słuchania", "Średni poziom depresji")
```

Po zdekodowaniu poziomu depresji (Low = 0, Medium = 1, High = 2) zauważalne są niewielkie, ale interesujące różnice w średnich wartościach w zależności od gatunku i częstotliwości słuchania muzyki. Najwyższy poziom depresji (1.19) występuje u osób czasami słuchających metalu, natomiast najniższy (0.64) – u osób bardzo często słuchających gospel, co może sugerować możliwy wpływ duchowości lub wieku słuchaczy. Osoby unikające gatunków takich jak metal, rap czy hip-hop również charakteryzują się niższym średnim poziomem depresji, choć może to wynikać z innych czynników – jak wiek, styl życia czy preferencje kulturowe. Ogólnie poziomy depresji oscylują wokół wartości 1, a różnice nie są duże, jednak dla niektórych gatunków zauważalne są pewne wzorce.

#### Średni poziom depresji dla każdej częstotliwości słuchania

```{r, echo=FALSE}
plot_mean_barplot(long_freq_depr, "Depression", "Średni poziom depresji dla każdej częstotliwości słuchania", "Średni poziom depresji") + 
  ylim(0, 2)
```

Średni poziom depresji nieznacznie (nieistotnie) wzrasta wraz ze zwiększającą się częstotliwością słuchania muzyki. Choć różnice są niewielkie, może to sugerować, że osoby częściej sięgające po muzykę – zwłaszcza intensywnie – częściej też deklarują średni lub wysoki poziom depresji. Może to wynikać z faktu, że muzyka bywa wykorzystywana jako forma wsparcia emocjonalnego, szczególnie przez osoby zmagające się z pogorszonym samopoczuciem. To jednak tak drobne zmiany, że trudno wyciągać z nich pewne wnioski.

#### Średnia liczba godzin słuchania muzyki według gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_mean_heatmap(data, "Hours per day", "Średnia liczba godzin słuchania muzyki według gatunku i częstotliwości słuchania", "Liczba godzin")
```

Z wykresu wynika, że jeśli dana osoba deklaruje częste słuchanie muzyki danego gatunku, to więcej czasu jej poświęca ogółem — co jest zgodne z intuicją. Gatunki takie jak rap, muzyka latynoska i hip-hop osiągają najwyższe średnie wartości godzin wśród osób słuchających muzyki bardzo często, co może świadczyć o ich intensywnej konsumpcji. Warto jednak zwrócić uwagę, że nawet osoby, które deklarują brak kontaktu z danym gatunkiem, często ogółem spędzają na słuchaniu muzyki znaczną liczbę godzin. Może to sugerować, że ich preferencje są silnie skierowane ku innym gatunkom, a nie że unikają muzyki jako takiej. Różnice w średniej liczbie godzin między grupami częstotliwości są widoczne, ale w wielu przypadkach niezbyt duże.

#### Średni czas słuchania muzyki według częstotliwości słuchania

```{r, echo=FALSE}
plot_mean_barplot(long_freq, "Hours per day", "Średni czas słuchania muzyki według częstotliwości słuchania", "Liczba godzin") + 
  ylim(0, 5)
```

Zanim przejdziemy do analizy, warto zaznaczyć, że słupek „Never” nie odnosi się do osób, które w ogóle nie słuchają muzyki, lecz do liczby gatunków, których ktoś nie słucha wcale. Osoby deklarujące bardzo częste słuchanie muzyki spędzają na tym najwięcej czasu, podczas gdy osoby słuchające jej rzadziej poświęcają jej odpowiednio mniej czasu. Każda kolejna grupa częstotliwości charakteryzuje się nieco wyższym średnim czasem słuchania, co świadczy o spójności deklaracji z rzeczywistym zaangażowaniem czasowym. Może to również potwierdzać, że częstotliwość słuchania stanowi dobry wskaźnik ogólnej intensywności kontaktu z muzyką. Wzrost ten jest jednak stosunkowo nieduży.

#### Średni wiek słuchającego w zależności od gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_mean_heatmap(df, "Age", "Średni wiek słuchającego w zależności od gatunku i częstotliwości słuchania", "Wiek")
```

Ogólnie można zauważyć, że osoby, które słuchają muzyki bardzo często, są zazwyczaj młodsze od tych, które robią to rzadziej lub deklarują brak kontaktu z danym gatunkiem. Najniższe średnie wieki występują wśród intensywnych słuchaczy gatunków takich jak K-pop, pop, rap, video game music czy lofi, co potwierdza ich popularność wśród młodszych odbiorców. Z kolei najwyższe wartości średniego wieku pojawiają się wśród osób słuchających częściej muzyki klasycznej, gospel, country czy rocka, co może wskazywać na większe zainteresowanie tymi gatunkami wśród starszych grup. Wzorce te są spójne z ogólnymi trendami demograficznymi w odbiorze muzyki.

#### Średni wiek słuchającego według częstotliwości słuchania

```{r, echo=FALSE}
plot_mean_barplot(long_freq_age, "Age", "Średni wiek słuchającego według częstotliwości słuchania", "Wiek") + 
  ylim(0, 30)
```

Można zauważyć, że osoby słuchające muzyki bardzo często są średnio wyraźnie młodsze (23.54) niż pozostałe grupy. W przypadku pozostałych kategorii – Never, Rarely i Sometimes – różnice są niewielkie i oscylują wokół 25–26 lat. Może to sugerować, że intensywne słuchanie muzyki jest szczególnie charakterystyczne dla młodszych osób, natomiast w starszych grupach wiekowych częstotliwość słuchania rozkłada się bardziej równomiernie.

#### Proporcja liczby osób słuchających z daną częstotliwością słuchania ulubionego gatunku do wszystkich osób słuchających tego gatunku z tą częstotliwością słuchania

```{r, echo=FALSE}
long_freq %>% 
  mutate(is_fav = ifelse(Genre == `Fav genre`, 1, 0)) %>% 
  group_by(Genre, Frequency) %>% 
  summarise(total = n(), fav_count = sum(is_fav, na.rm = TRUE), prop = fav_count / total, .groups = "drop") %>% 
  ggplot(aes(x = Genre, y = Frequency, fill = prop)) + 
  geom_tile(color = "white") + 
  geom_text(aes(label = round(prop, 2)), color = "black", size = 3) + 
  scale_fill_gradient(low = "lightyellow", high = "darkblue") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  labs(title = "Udział ulubionych gatunków wśród słuchaczy danego gatunku i częstotliwości", x = "Gatunek", y = "Częstotliwość słuchania", fill = "Udział ulubionych")
```

Silna preferencja ulubionego gatunku wiąże się z jego regularnym słuchaniem (Very frequently). Oczywiście dla pozostałych kategorii częstotliwości (Sometimes, Rarely, Never) udział ulubionych gatunków jest znikomy lub zerowy. Wizualizacja pokazuje, że osoby słuchające bardzo często gatunków takich jak metal, country czy rock, znacznie częściej wskazują je jako ulubione – w przeciwieństwie do słuchaczy lofi, latin czy rapu. Może to wynikać z faktu, że metal, country i rock są silnie związane z konkretnymi subkulturami i tożsamością słuchaczy, częściej spotykaną wśród starszych odbiorców z bardziej ugruntowanymi gustami muzycznymi. Natomiast młodsi słuchacze, którzy dominują wśród fanów rapu, lofi czy latino, często słuchają wielu różnych gatunków, niekoniecznie mając jeden ulubiony – co może odzwierciedlać większą otwartość i zmienność preferencji. Dodatkowo, gatunki takie jak lofi czy latin mogą być słuchane bardziej użytkowo (np. do nauki, relaksu, zabawy), a nie emocjonalnie, co także może ograniczać ich postrzeganie jako „ulubionych”.

#### Udział muzyków wśród słuchaczy danego gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_binary_heatmap(long_bin_all, "Instrumentalist") +
  labs(title = "Udział muzyków wśród słuchaczy danego gatunku i częstotliwości słuchania", fill = "Udział muzyków")
```

Wykres pokazuje, że najwyższy udział muzyków wśród słuchaczy „Very frequently” dotyczy muzyki klasycznej (60%) i jazzu (57%) – oba te gatunki są silnie powiązane z formalnym wykształceniem muzycznym, wymagają dużych umiejętności technicznych i są obecne w edukacji muzycznej, co przyciąga osoby aktywnie grające. Odwrotnie sytuacja wygląda dla country, hip-hopu i R&B, gdzie udział muzyków jest relatywnie niski nawet wśród częstych słuchaczy – sugeruje to, że te gatunki są bardziej konsumenckie, tzn. słuchane głównie przez osoby nieuprawiające muzyki. Ciekawym zjawiskiem jest to, że osoby, które w ogóle nie słuchają popu, R&B, rapu, hip-hopu czy rocka, częściej są muzykami – może to wynikać z bardziej klasycznego lub niszowego gustu muzycznego muzyków, którzy unikają komercyjnych gatunków na rzecz tych bardziej technicznych, instrumentalnych lub poważnych.

#### Udział kompozytorów wśród słuchaczy danego gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_binary_heatmap(long_bin_all, "Composer") +
  labs(title = "Udział kompozytorów wśród słuchaczy danego gatunku i częstotliwości słuchania", fill = "Udział kompozytorów")
```

Wśród bardzo częstych słuchaczy jazzu, klasyki i metalu jest najwyższy odsetek kompozytorów – odpowiednio 40%, 22% i 25% – co może wynikać z ich muzycznej złożoności. Z kolei country, hip-hop, rap, R&B czy K-pop przyciągają mniej kompozytorów, nawet wśród często słuchających. Może to wynikać z faktu, że często opierają się na powtarzalnych schematach lub prostszych strukturach co przyciąga mniej kompozytorów. Jednak może to być jedynie charakterystyczna zależność dla tego zbioru danych.

#### Udział słuchaczy muzyki w trakcie pracy/nauki względem gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_binary_heatmap(long_bin_all, "While working") +
  labs(title = "Proporcja słuchaczy muzyki w trakcie pracy/nauki względem gatunku i częstotliwości słuchania", fill = "Udział przy pracy/nauce")
```

Większość często słuchanych gatunków muzycznych jest również wykorzystywana podczas pracy lub nauki. Nieco niższy udział (0.82 i mniej) obserwujemy w przypadku takich gatunków jak country, pop, metal czy rock – są to zazwyczaj utwory bardziej dynamiczne i angażujące, co może rozpraszać, dlatego rzadziej towarzyszą nauce czy pracy. Na tle innych wyraźnie wyróżnia się lofi, który osiąga prawie 90% udziału w słuchaniu podczas pracy/nauki. Co ciekawe, wśród osób, które go nie słuchają na co dzień, współczynnik ten jest najniższy w całym zestawieniu (0.68). Może to wynikać z faktu, że lofi to muzyka relaksująca, mało angażująca i najczęściej pozbawiona słów – jakby stworzona do towarzyszenia w skupieniu i pracy umysłowej.

#### Udział aktywnie eksplorujących nowe gatunki i autorów względem gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_binary_heatmap(long_bin_all, "Exploratory") +
  labs(title = "Udział aktywnie eksplorujących nowe gatunki i autorów względem gatunku i częstotliwości słuchania", fill = "Udział eksplorujących")
```

Osoby często słuchające rapu i jazzu wykazują wysoką skłonność do eksplorowania nowych wykonawców i gatunków, co może wynikać z dynamicznego charakteru tych stylów – rap nieustannie się zmienia i przyciąga nowymi trendami, a jazz opiera się na improwizacji i fuzjach, co naturalnie sprzyja otwartości na nowe brzmienia. W przeciwieństwie do tego, osoby bardzo często słuchające gospelu mają niski współczynnik eksploracji (0,5), co może być związane z silnym emocjonalnym i duchowym przywiązaniem do konkretnych utworów i wykonawców – w tym przypadku muzyka pełni bardziej stałą, rytualną funkcję niż rozrywkową. Ciekawa jest też sytuacja popu – wśród osób, które deklarują, że go nie słuchają, eksploracja muzyczna jest bardzo niska. Może to wynikać z faktu, że pop jest wszędzie obecny i trudno go zupełnie uniknąć; jeśli ktoś to robi, najczęściej świadomie ogranicza się do jednego, alternatywnego stylu, rezygnując z poszukiwania nowych brzmień.

#### Udział słuchaczy muzyki w językach obcych dla nich względem gatunku i częstotliwości słuchania

```{r, echo=FALSE}
plot_binary_heatmap(long_bin_all, "Foreign languages") +
  labs(title = "Udział słuchaczy muzyki w językach obcych dla nich względem gatunku i częstotliwości słuchania", fill = "Udział w języku obcym")
```

W danych wyraźnie widoczne są istotne różnice między gatunkami pod względem udziału muzyki w językach obcych. K-pop (95%) i Latin (85%) to gatunki, które są niemal zawsze słuchane w językach innych niż ojczysty – co wynika z ich międzynarodowego charakteru i popularności poza krajem pochodzenia słuchaczy. Z kolei Gospel (36%) i Country (41%) mają najniższy udział muzyki obcojęzycznej, nawet wśród osób słuchających ich bardzo często. Są to style silnie związane z lokalną tradycją i tożsamością kulturową, przez co rzadziej występują w wersjach językowo zróżnicowanych.

## Imputacja i usuwanie brakujących danych

```{r, include=FALSE}
df <- df %>% 
        mutate(Depression = case_when(Depression <= 3 ~ "Low",
                                      Depression > 3 & Depression < 7 ~ "Medium",
                                      Depression >= 7 ~ "High"),
               Depression = factor(Depression, levels = c("Low", "Medium", "High")))
```

#### Liczba braków danych

```{r}
sum(is.na(df))
```

#### Liczba braków danych dla każdej kolumny

```{r}
colSums(is.na(df))
```

Braki danych występują w kilku kolumnach, jednak w większości przypadków jest ich bardzo niewiele. Najwięcej braków znajduje się w kolumnie BPM, gdzie odnotowano 107 brakujących wartości.

#### Liczba braków danych dla wierszy

```{r}
res <- md.pattern(df, plot = TRUE, rotate.names = TRUE)
```

Mamy 104 obserwacje z pojedyńczym brakiem danych w kolumnie BPM. Pozostałe braki danych są już jednostkowe. Mamy jedną obserwację gdzie brakuje 5 wartości, ponieważ jest tylko jedna to taką obserwację poprostu usuwamy. Braki danych z kolumny BPM uzupełnimy średnimi grupowymi dla konkretnych gatunków muzycznych, ponieważ w ten sposób dane będą bardziej rzeczywiste niż gdybyśmy uzupełnili je średnią dla całej kolumny.

#### Odstające wartości w kolumnie BPM

```{r}
data$BPM[data$BPM >= 600 | data$BPM <= 20] <- NA
```

Nierealne wartości BPM (8 obserwacji) zastąpiliśmy brakami danych, ponieważ lepsze to niż tracenie informacji.

#### Uzupełnianie braków danych w kolumnie BPM

```{r}
means <- aggregate(BPM ~ `Fav genre`, data = data, FUN = function(x) round(mean(x[x > 0], na.rm = TRUE), 0))
```

```{r}
set.seed(123)

idx <- which(is.na(data$BPM))
values <- numeric(length(idx))

m <- rnorm(length(idx), mean = 1, sd = 0.05)

for (j in 1:115) {
  genre <- data$`Fav genre`[idx[j]]
  base <- means[means$`Fav genre` == genre, 'BPM']
  values[j] <- base * m[j]
}

data$BPM[idx] <- round(values, 0)
```

Braki danych w zmiennej BPM zostały uzupełnione średnimi grupowymi z dodaniem losowego szumu, a następnie zaokrąglone do wartości całkowitych, ponieważ tylko takie wartości mają sens logiczny w kontekście BPM.

#### Wartości którymi wypełniono braki danych w kolumnie BPM

```{r}
data[idx, c("Fav genre", "BPM")] %>%
  mutate(Index = idx) %>%
  select(Index, `Fav genre`, BPM) %>%
  arrange(`Fav genre`)
```

#### Sprawdzenie jakie braki danych nam zostały po usunięciu tych z kolumny BPM

```{r}
res <- md.pattern(data, plot = TRUE, rotate.names = TRUE)
```

#### Usunięcie wiersza z czterema brakami danych

```{r}
data <- data[rowSums(is.na(data)) != 4, ] 
```

Po usunięciu pojedyńczego wiersza z 4 brakami danych pozostają już nam jedynie obserwacje z pojedyńczymi brakami. Uzupełnimy je proprzez imputację z wykorzystaniem pakietu `mice`.

```{r, warning=FALSE}
set.seed(2025)

colnames(data) <- make.names(colnames(data))

imp <- mice(data,
            m = 1,
            seed = 2025,
            printFlag = F)


data <- complete(imp,1)
```

#### Rezultat usuwania i uzupełniania braków danych

```{r}
res <- md.pattern(data, plot = TRUE, rotate.names = TRUE)
```

Jak widać pozostają nam 735 obserwacje bez braków danych.

#### Zapisywanie zbioru danych po uzupełnieniu oraz usunięciu wszystkich braków danych

```{r}
#saveRDS(data, "data_no_missing_values.rds")
```

## Budowa modeli

### Wstępne modelowanie

```{r, include=FALSE}
df <- readRDS("data_no_missing_values.rds")
```

#### Podział danych na zbiór treningowy i testowy

```{r}
set.seed(123)

split <- initial_split(df, prop = 0.8, strata = "Depression")
train <- training(split)
test <- testing(split)
```

Dzielimy dane na zbiór uczący oraz testowy z zachowaniem proporcji klas w kolumnie `Depression`.

#### Inicjalizacja modeli do uczenia

```{r}
models <- list(
            nb = naive_Bayes(mode = "classification",
                             engine = "klaR"),
            
            svm = svm_rbf(mode = "classification",
                         engine = "kernlab"),
            
            dt = decision_tree(mode = "classification",
                               engine = "rpart"),
            
            mlp = mlp(mode = "classification",
                      engine = "nnet"),
            
            knn = nearest_neighbor(mode = "classification",
                                   engine = "kknn"),
            
            rf = rand_forest(mode = "classification",
                             engine = "ranger"),
  
            xgb = boost_tree(mode = "classification",
                             engine = "xgboost"),
  
            lda = discrim_linear(mode = "classification",
                                 engine = "MASS")
)
```

Inicjalizujemy listę modeli kolejno: Naive Bayes, SVM, Decision Tree, MLP, KNN, Random Forest, XGBoost oraz LDA. Celem tego etapu jest wstępna ocena skuteczności różnych rodzin modeli na naszych danych. Na podstawie uzyskanych wyników wybierzemy cztery najlepiej rokujące algorytmy, które następnie zostaną poddane dalszej analizie i dostrajaniu hiperparametrów.

#### Utworzenie przepisów przetwarzania danych

```{r}
recipes <- list(
            rec_norm = recipe(Depression ~ ., data = train) %>%
                        step_normalize(all_numeric_predictors())  %>%
                        step_dummy(all_nominal_predictors()),
            
            rec_pca_60 = recipe(Depression ~ ., data = train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(all_predictors(), threshold = 0.6),
            
            rec_pca_80 = recipe(Depression ~ ., data = train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(all_predictors(), threshold = 0.8)
)
```

Będziemy testować modele na różnych poziomach PCA. Przetestowanie modeli z różnymi wariantami przygotowania danych pozwoli na ocenę, która metoda wstępnego przetwarzania jest najkorzystniejsza dla danego algorytmu.

#### Utworzenie przepływów modelowania

```{r}
wflows <- workflow_set(
            preproc = recipes,
            models = models,
            cross = TRUE
)
```

Tworzymy obiekt workflow_set z flagą cross=TRUE, czyli każdy model zostanie przetestowany na każdym przepisie.

#### Generowanie foldów walidacyjnych

```{r}
folds <- vfold_cv(train, v = 10)
```

Tworzymy 10-krotną walidację krzyżową na zbiorze treningowym.

#### Trenowanie modeli

```{r, eval=FALSE}
registerDoParallel(cores = parallel::detectCores() - 1)
keep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)

initial_wflows <- wflows %>% 
                    workflow_map(
                      "fit_resamples",
                      resamples = folds,
                      control = keep_pred,
                      verbose = FALSE
)
```

Na tym etapie przeprowadzamy trenowanie wszystkich wcześniej przygotowanych modeli z wykorzystaniem walidacji krzyżowej. Dzięki temu możemy porównać ich skuteczność oraz wyłonić te algorytmy, które najlepiej radzą sobie z naszym problemem.

#### Wyniki dla procesu modelowania

```{r, include=FALSE}
initial_wflows <- readRDS("mxmh_initial_models.rds")
```

```{r}
initial_wflows %>%
  collect_metrics() %>% 
  group_by(.metric) %>% 
  arrange(.metric, desc(mean))
```

Ze wstępnych wyników do dalszej części weźmiemy modele LDA, Random Forest, SVM oraz XGBoost.

#### Zapisanie wyników wstępnego modelowania

```{r}
#saveRDS(wflows, "mxmh_initial_models.rds")
```

### Dostrajanie hiperparametrów wybranych modeli

#### Podział danych na zbiór treningowy i testowy

```{r}
set.seed(123)

df_split <- initial_split(df, prop = 0.75, strata = "Depression")
df_train <- training(df_split)
df_test <- testing(df_split)
```

Nie mamy zbyt wiele danych do testowania, dlatego do tej części uczenia użyjemy 75% danych.

#### Inicjalizacja modeli do treningu i strojenia hiperparametrów najlepszych algorytmów

```{r}
models <- list(
            lda = discrim_linear(
              regularization_method = "diagonal",
              penalty = tune(),
              mode = "classification") %>% 
              set_engine("mda"),
              
            rf = rand_forest(
              trees = tune(),
              min_n = tune(),
              mtry = tune(),
              mode = "classification") %>%
              set_engine("ranger"),
  
            xgb = boost_tree(
              trees = tune(),
              min_n = tune(),
              mtry = tune(),
              learn_rate = tune(),
              mode = "classification") %>%
              set_engine("xgboost"),
  
            svm = svm_rbf(
              cost = tune(),
              rbf_sigma = tune(),
              mode = "classification") %>%
              set_engine("kernlab")
)
```

Inicjalizujemy cztery modele, które osiągnęły najlepsze wyniki w etapie wstępnego trenowania. Modele te zostaną teraz poddane strojeniu hiperparametrów w celu dalszej poprawy ich skuteczności.

#### Utworzenie przepisów przetwarzania danych

```{r}
recipes <- list(
            rec_lda = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.85, prefix = "pca_"),
            
            rec_rf = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors())  %>%
                        step_dummy(all_nominal_predictors()) %>% 
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.85, prefix = "pca_") %>% 
                        step_nzv(all_predictors()),

            rec_xgb = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.85, prefix = "pca_")%>% 
                        step_nzv(all_predictors()),
            
            rec_svm = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.8, prefix = "pca_") 
)
```

Dobór przepisów został dokonany ze względu na to jaka jest struktura naszego zbioru danych, tj. mamy wiele kolumn typu factor oraz powiązanych ze sobą ze względu na dziedzinę jak chociażby częstotliwość słuchania różnych gatunków. Ponadto odpowiedzi są subiektywne dlatego nie niosą czystej informacji.

#### Utworzenie przepływów modelowania

```{r}
class_models <- workflow_set(
                  preproc = recipes,
                  models = models,
                  cross = FALSE
)
```

Tym razem uczenie będzie przebiegało w formie jeden model do jednego przepisu.

#### Generowanie foldów walidacyjnych

```{r}
cv_folds <- vfold_cv(df_train, v = 5, strata = "Depression")
```

Tym razem wykrozystamy 5-krotną walidację krzyżową.

#### Trenowanie modeli z walidacją krzyżową i tuningiem siatki hiperparametrów

```{r, eval=FALSE}
registerDoParallel(cores = parallel::detectCores() - 1)
controlGrid <- control_grid(save_pred = TRUE, save_workflow = TRUE, verbose = TRUE)

class_models <- workflow_map(
                  class_models,
                  "tune_grid", 
                  resamples = cv_folds,
                  grid = 50,
                  control = controlGrid,
                  metrics = metric_set(mn_log_loss, kap),
                  verbose = TRUE,
)
```

Model będzie optymalizowany pod kątem metryki mn_log_loss, która jest dobrze dopasowana do problemów klasyfikacji wieloklasowej, ponieważ uwzględnia pewność predykcji. Do strojenia używamy siatki z 50 kombinacjami, co zapewnia wystarczającą różnorodność konfiguracji hiperparametrów, pozwalając na znalezienie optymalnych ustawień.

#### Zapisywanie wyników dostrajania hiperparametrów

```{r}
#saveRDS(class_models, "mxmh_models_kap3.rds")
```

```{r, include=FALSE}
class_models <- readRDS("mxmh_models_kap3.rds")
```

#### Ocena modeli

```{r}
metrics <- collect_metrics(class_models)

metrics %>% 
  arrange(.metric, desc(mean))
```
Niskie wyniki kappa co sugeruje nam już, że modele miały problem z przewidywaniem

#### Najlepsze parametry dla każdego z czterech modeli

```{r}
best_params_list <- class_models %>%
                      mutate(best = map(result, ~ select_best(.x, metric = "mn_log_loss"))) %>%
                      select(wflow_id, best)

lda_params <- best_params_list$best[[1]]
rf_params <- best_params_list$best[[2]]
xgb_params <- best_params_list$best[[3]]
svm_params <- best_params_list$best[[4]]
```

Tworzymy listę najlepszych parametrów dla każdego z modeli startowych.

#### Deklaracja modeli z najlepszymi hiperparametrami

```{r}
models_final <- list(
            lda = discrim_linear(
              regularization_method = "diagonal",
              penalty = lda_params[[1]],
              mode = "classification") %>% 
              set_engine("mda"),
              
            rf = rand_forest(
              trees = rf_params[[2]],
              min_n = rf_params[[3]],
              mtry = rf_params[[1]],
              mode = "classification") %>%
              set_engine("ranger"),
  
            xgb = boost_tree(
              trees = xgb_params[[2]],
              min_n = xgb_params[[3]],
              mtry = xgb_params[[1]]	,
              learn_rate = xgb_params[[4]],
              mode = "classification") %>%
              set_engine("xgboost"),
  
            svm = svm_rbf(
              cost = svm_params[[1]],
              rbf_sigma = svm_params[[2]],
              mode = "classification") %>%
              set_engine("kernlab")
)
```

Deklarujemy cztery modele z wcześniej wybranymi najlepszymi zestawami hiperparametrów, Parametry te zostały wytypowane na podstawie wyników strojenia w poprzednim etapie,co pozwala nam teraz przeprowadzić finalne trenowanie każdego z modeli na zbiorze treningowym.

#### Przygotowanie przepisów przetwarzania danych do finalnego trenowania modeli

```{r}
recipes <- list(
            rec_lda = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.9, prefix = "pca_"),
            
            rec_rf = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors())  %>%
                        step_dummy(all_nominal_predictors()) %>% 
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.9, prefix = "pca_") %>% 
                        step_nzv(all_predictors()),

            rec_xgb = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.9, prefix = "pca_")%>% 
                        step_nzv(all_predictors()),
            
            rec_svm = recipe(Depression ~ ., data = df_train) %>%
                        step_normalize(all_numeric_predictors()) %>%
                        step_dummy(all_nominal_predictors()) %>%
                        step_pca(starts_with("Frequency"), num_comp = 12) %>% 
                        step_pca(all_predictors(), threshold = 0.9, prefix = "pca_") 
)
```

W tym etapie przygotowujemy osobne przepisy przetwarzania danych dla każdego modelu, wykorzystując pełny zbiór treningowy (bez walidacji krzyżowej). Dzięki temu modele będą mogły uczyć się na większej liczbie danych.


### Deklaracja workflowów z ostatecznymi modelami i przepisami

```{r, warning=FALSE}
# LDA
final_wf_lda <- workflow() %>%
  add_model(models_final$lda) %>%
  add_recipe(recipes$rec_lda)

fit_lda <- fit(final_wf_lda, df_train)

# Random Forest
final_wf_rf <- workflow() %>%
  add_model(models_final$rf) %>%
  add_recipe(recipes$rec_rf)

fit_rf <- fit(final_wf_rf, df_train)

# XGBoost
final_wf_xgb <- workflow() %>%
  add_model(models_final$xgb) %>%
  add_recipe(recipes$rec_xgb)

fit_xgb <- fit(final_wf_xgb, df_train)

# SVM
final_wf_svm <- workflow() %>%
  add_model(models_final$svm) %>%
  add_recipe(recipes$rec_svm)


fit_svm <- fit(final_wf_svm, df_train)
```

Przeprowadzamy ostateczne uczenie modeli, tym razem z konkretnymi hiperparametrami i na całym zbiorze treningowym. Każdy model jest trenowany oddzielnie
Tworzymy nowe workflowy dla każdego z modeli z ostatecznymi parametrami z osobna. Wszystkie modele mają zbierać metrykę mn_log_loss, którą uznaliśmy za najbardziej adekwatną dla problemu.

### Nauka oraz ocena ostatecznych modeli

```{r}
levels_order <- c("Low", "Medium", "High")

preds_lda <- bind_cols(
  predict(fit_lda, df_test, type = "prob"),
  predict(fit_lda, df_test),
  df_test %>% select(Depression)
) %>% adjust_levels()

preds_rf <- bind_cols(
  predict(fit_rf, df_test, type = "prob"),
  predict(fit_rf, df_test) ,
  df_test %>% select(Depression)
) %>% adjust_levels()

preds_xgb <- bind_cols(
  predict(fit_xgb, df_test, type = "prob"),
  predict(fit_xgb, df_test),
  df_test %>% select(Depression)
) %>% adjust_levels()

preds_svm <- bind_cols(
  predict(fit_svm, df_test, type = "prob"),
  predict(fit_svm, df_test),
  df_test %>% select(Depression)
) %>% adjust_levels()

lda_tr <-  bind_cols(
    predict(fit_lda, df_train, type = "prob"),
    predict(fit_lda, df_train),
    df_train %>% select(Depression)
  ) %>% adjust_levels()
  
rf_tr <-  bind_cols(
  predict(fit_rf, df_train, type = "prob"),
  predict(fit_rf, df_train),
  df_train %>% select(Depression)
) %>% adjust_levels()

xgb_tr  <-  bind_cols(
  predict(fit_xgb, df_train, type = "prob"),
  predict(fit_xgb, df_train),
  df_train %>% select(Depression)
) %>% adjust_levels()

svm_tr <-  bind_cols(
  predict(fit_svm, df_train, type = "prob"),
  predict(fit_svm, df_train),
  df_train %>% select(Depression)
) %>% adjust_levels()
```

W tej części przeprowadziliśmy zebranie predykcji na zbiorze testowym oraz treningowym.

### Macierze kontyngencji dla ostatecznych modeli

```{r}
conf_df <- tibble(
  model = c("lda", "rf", "xgb", "svm"),
  confusion_matrix = list(
    conf_mat(preds_lda, truth = Depression, estimate = .pred_class),
    conf_mat(preds_rf,  truth = Depression, estimate = .pred_class),
    conf_mat(preds_xgb, truth = Depression, estimate = .pred_class),
    conf_mat(preds_svm, truth = Depression, estimate = .pred_class)
  )
)

conf_df$confusion_matrix
```

Macierze kontygnencji dla kolejno modeli lda, rf, xgb oraz svm dla predykcji na zbiorze testowym. Widać, że modele nie poradziły sobie najlepiej z zadaniem. Największe problemy występują z przewidywaniem klasy medium, może to sugerować, że niedoceniliśmy losowości w samoocenie depresji wśród respondentów i lepszym podziałem mógł okazać się podział na dwie klasy, bądź dalej 3 klasy, ale w innych kwantylach. Pocieszający jest  fakt, że modele nie radzą sobie najgorzej z przewidywaniem klasy low i high osiągając przeciętnie 50% dokładności w tych klasach co jest lepsze niż model losowy, który dałby 33%.


### Metryki
```{r}
metric_eval <- metric_set(mn_log_loss, kap)

preds_train <- list(
  lda = lda_tr,
  rf = rf_tr,
  xgb = xgb_tr,
  svm = svm_tr
)

preds_test <- list(
  lda = preds_lda,
  rf  = preds_rf,
  xgb = preds_xgb,
  svm = preds_svm
)
```


```{r}
train_metrics <- map_dfr(names(preds_train), ~ {
  get_metrics(preds_train[[.x]]) %>%
    mutate(model = .x, dataset = "df_train")
}) # Dla każdego modelu pobieramy metryki w tym przypadku dla zbioru treningowego, niżej będzie to samo dla testowego, dodajemy kolumnę jaki to model oraz jaki zbiór a na koniec łączymy to wszystko w jeden data drame

test_metrics <- map_dfr(names(preds_test), ~ {
  get_metrics(preds_test[[.x]]) %>%
    mutate(model = .x, dataset = "df_test")
})

final_metrics <- bind_rows(train_metrics, test_metrics) %>%
  select(model, dataset, .metric, .estimate) %>% # wybranie kolumn wszystkich poza .estimator i przearanżowanie kolejności dla lepszej czytelności
  pivot_wider(names_from = .metric, values_from = .estimate) # pivotujemy po metrykach by móc obserwować obie metryki jedna obok drugiej

final_metrics %>% 
  arrange(dataset, mn_log_loss, desc(kap))
```

Ogromne przeuczenie modelu random forest, duże przeuczenie dla xgboost, svm. Model lda jako jedyny wyszedł stabilny dlatego to go wybieramy jako model ostateczny.


### Podsumowanie

W przeprowadzonym projekcie klasyfikacji depresji na podstawie nawyków słuchania muzyki wykorzystaliśmy znane nam narzędza eksploracyjne, przygotowania danych, wyboru modeli, strojenia hiperparametrów i walidacji krzyżowej. Dane zostały oczyszczone i uzupełnione metodą imputowania (mice). Przetestowaliśmy wiele podejść do preprocesingu (m.in. normalizacja, PCA) oraz szeroki zakres klasyfikatorów: Naive Bayes, SVM, drzewo decyzyjne, MLP, KNN, Random Forest, XGBoost, LDA.

Najlepsze wyniki uzyskano dla modeli: Random Forest, SVM, XGBoost oraz LDA. W ich przypadku przeprowadzono dokładne strojenie hiperparametrów oraz analizę metryk (mn_log_loss oraz kap). Ostatecznie najbardziej stabilnym modelem okazał się LDA, który osiągnął najlepsze wyniki na zbiorze testowym, jednak nadal z niską dokładnością. Pozostałe modele, mimo że wykazywały lepsze wyniki na zbiorze treningowym, przejawiały silne przeuczenie i nie były w stanie generalizować na nowych danych.

Pomimo pełnego zaangażowania i wykorzystania dostępnych środków, modele nie osiągnęły oczekiwanej stabilności i jednoznacznej przewagi jednego podejścia, co wynika prawdopodobnie z ograniczeń samego zbioru danych – w szczególności: niewielkiej liczby obserwacji, dużej liczby zmiennych po imputacji, charakterystyką przeprowadzonej ankiety (tj. respondenci odpowiadali wedle własnej samooceny, nie według oceny osoby z wykształceniem psychologicznym) oraz złożonej, nieliniowej zależności pomiędzy słuchaniem muzyki a stanem emocjonalnym.

Naszym zdaniem projekt może nie jest idealny, ale napewno nie jest też rozczarowywujący, ponieważ jak na jakość danych udało się odnaleźć jakiekolwiek zależności w tym zbiorze dostając przy tym predykcje, które są lepsze niż takie w pełni losowe.
